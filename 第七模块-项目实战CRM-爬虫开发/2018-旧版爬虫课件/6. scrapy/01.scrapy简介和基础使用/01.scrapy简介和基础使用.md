Scrapy框架课程介绍：

1.   框架的简介和基础使用

2.   持久化存储

3.   代理和cookie

4.   日志等级和请求传参

5.   CrawlSpider

6.   基于redis的分布式爬虫



一． scrapy框架的简介和基础使用 

a) 概念：为了爬取网站数据而编写的一款应用框架，出名，强大。所谓的框架其实就是一个集成了相应的功能且具有很强通用性的项目模板。（高性能的异步下载，解析，持久化……）

b) 安装：

​	-  linux mac  os :  

```
 pip  install scrapy
```

   - win:

     ```
     1.pip install wheel
     2.下载twisted：https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted
     	pip install 下载好的框架.whl
     3.pip install pywin32
     4.pip install scrapy
     ```

     

C)  基础使用： 使用流程

​	i. 创建一个工程：

```
scrapy startproject 工程名称
```

目录结构

```text
project_name/
	scrapy.cfg:
	project_name/
			__init__.py
			items.py
			piplines.py
			settings.py
			spiders/
					__init__.py

scrapy.cfg  项目的主配置信息.(真正爬虫相关的配置在settings.py 文件中
items.py    设置数据存储模板,用于结构化数据, 如: Django的model
pipelines   数据持久化处理
settings.py 配置文件,如: 递归的层数\ 并发数 \ 延迟下载等
spiders     爬虫目录, 如: 创建文件, 编写爬虫解析规则


```

 ii. 在工程目录下创建一个爬虫文件:

```
cd 工程
scrapy genspider 爬虫文件的名称  起始url
```

iii. 对应的文件中编写爬虫程序来完成爬虫的相关操作

iv. 配置文件的编写（settings）

```
1.19行：对请求载体的身份进行伪装
2.22行：不遵从robots协议
```

v.  执行

```
scrapy crawl 爬虫文件的名称   --nolog(阻止日志信息的输出)
```













