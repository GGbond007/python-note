Request URL: http://192.168.10.43/
Request Method: GET
Status Code: 200 OK
Remote Address: 192.168.10.43:80
Referrer Policy: no-referrer-when-downgrade

Response headers
Accept-Ranges: bytes
Connection: keep-alive
Content-Length: 6
Content-Type: text/html
Date: Fri, 26 Oct 2018 12:43:02 GMT
ETag: "5bd3014d-6"
Last-Modified: Fri, 26 Oct 2018 11:58:05 GMT
Server: nginx/1.15.5

Request Headers
GET /index.php HTTP/1.1
Host: 192.168.10.43
Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) 
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/
537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/
webp,image/apng,*/*;q=0.8
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9


⼀、实现⼀个基本Nginx集群
web业务服务器设置
#web01
[root@web01 ~]# sh nginx_install
[root@web01 ~]# echo web01 > /usr/local/nginx/html/index.html 
[root@web01 ~]# /usr/local/nginx/sbin/nginx 
[root@web01 ~]# elinks http://localhost -dump
   web01

#web02
[root@web02 ~]# sh nginx_install
[root@web02 ~]# echo web02 > /usr/local/nginx/html/index.html 
[root@web02 ~]# yum -y install elinks &>/dev/null
[root@web02 ~]# /usr/local/nginx/sbin/nginx 
[root@web02 ~]# elinks http://localhost -dump
   web02

#nginx 分发器
[root@Master ~]# sh nginx_install
[root@Master ~]# sed -i '/#/d' /usr/local/nginx/conf/nginx.conf
[root@Master ~]# sed -i '/^$/d' /usr/local/nginx/conf/nginx.conf
[root@Master ~]# cat /usr/local/nginx/conf/nginx.conf
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;

#upstream 
upstream web {
server 192.168.10.42;
server 192.168.10.43;
}

    server {
        listen       80;
        server_name  localhost;
        location / {
                    proxy_pass http://web;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}

[root@Master ~]# /usr/local/nginx/sbin/nginx

#测试
[root@web02 ~]# elinks http://192.168.10.40 -dump
   web01
[root@web02 ~]# elinks http://192.168.10.40 -dump
   web02
[root@web02 ~]# elinks http://192.168.10.40 -dump
   web01
[root@web02 ~]# elinks http://192.168.10.40 -dump
   web02


upstream module

nginx的upstream⽬前⽀持4种⽅式的分配
1、轮询（默认）
每个请求按时间顺序逐⼀分配到不同的后端服务器，如果后端服务器down掉，能⾃动剔除。
2、weight
指定轮询⼏率，weight和访问⽐率成正⽐，⽤于后端服务器性能不均的情况。
3、ip_hash
每个请求按访问ip的hash结果分配，这样每个访客固定访问⼀个后端服务器，可以解决
session的问题。
4、fair（第三⽅）
按后端服务器的响应时间来分配请求，响应时间短的优先分配。
5、url_hash（第三⽅）
按访问url的hash结果来分配请求，使每个url定向到同⼀个后端服务器，后端服务器为缓
存时⽐较有效。

每个设备的状态设置为:
1.down 表示单前的server暂时不参与负载
2.weight 默认为1.weight越⼤，负载的权重就越⼤。
3.max_fails ：允许请求失败的次数默认为1.当超过最⼤次数时，返回
proxy_next_upstream 模块定义的错误
4.fail_timeout:失败超时时间，在连接Server时，如果在超时时间之内超过
max_fails指定的失败次数，会认为在fail_timeout时间内Server不可⽤。默认为
10s。
5.backup： 其它所有的⾮backup机器down或者忙的时候，请求backup机器。所以这台
机器压⼒会最轻。


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
nginx 分发器设置
默认采⽤RR算法，如果想采⽤其他算法，如ip_hash类似于LVS sh,例⼦

upstream apache {
        ip_hash;
        server 192.168.10.42;
        server 192.168.10.43;
}

  server {
        listen 80;
        server_name www.abc.com;
        location / {
        proxy_pass http://apache;
                }
   }

ip_hash算法能够保证来⾃同样源地址的请求，都分发到同⼀台主机

url_hash
http://ip/a.html 
需要⾃⼰重新编译nginx

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
基于权重

upstream web {
        server 192.168.10.42 weight=1;
        server 192.168.10.43 weight=2;   
}
   server {
        listen 80;
        server_name localhost;
        location / {
        proxy_pass http://web;
                }
   }


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
基于http协议主机头的分发

http ｛
 upstream web1 {
 server 192.168.10.42;
          }

          server {
        listen 80;
        server_name www.web1.com;
        location / {
         proxy_pass http://web1;
                }
        }
｝


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
基于语⾔的分发
要求各位完成php，html分发的基础上实现负载均衡

http { 

                      upstream php {
         server 192.168.10.42;
                    }

 upstream html {
         server 192.168.10.43;
                    }

                    server {
                      location ~* \.php$ {
        proxy_pass http://php;
                              }
                    }


                      location ~* \.html$ {
        proxy_pass http://html;
                              }

}

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
基于浏览器分发

upstream elinks { server 192.168.10.42; }
upstream chrome { server 192.168.10.43; }
upstream any { server 192.168.10.42:81; }

server {
                listen 80;
                server_name www.web1.com;
                
location / {
  proxy_pass http://any;
    
       if ( $http_user_agent ~* Elinks ) {
         proxy_pass http://elinks;
     }
        
      if ( $http_user_agent ~* chrome ) {
         proxy_pass http://chrome;
     }
  }
}

思考如果其他浏览器呢？  去访问/tmp/186⽂件夹下的⽹站。  elinks浏览器去访问245  
firefox访问246

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
http://192.168.10.40/a/b/c/index.php     http://192.168.10.42
基于源地址分发（类似于ACL DNS）
编译
./configure --with-http_geoip_module

upstream bj.server {
        server 192.168.10.42;
 }
upstream sh.server {
        server 192.168.10.43;
 }

upstream default.server {
        server 192.168.10.42:81;
 }

geo $geo {
        default default;
        192.168.10.241/32 bj;
        192.168.10.242/32 sh;
}

location / {
             proxy_pass http://$geo.server$request_uri;

        }


Keepalived的作⽤是检测服务器的状态，如果有⼀台web服务器宕机，或⼯作出现故障，
Keepalived将检测到，并将有故障的服务器从系统中剔除，同时使⽤其他服务器代替该服
务器的⼯作，当服务器⼯作正常后Keepalived⾃动将服务器加⼊到服务器群中，这些⼯作
全部⾃动完成，不需要⼈⼯⼲涉，需要⼈⼯做的只是修复故障的服务器。
运⾏协议 vrrp
主分发器的KP 会向⽹络中发组播 宣告⾃⼰还活着   224.0.0.18

安装在哪⾥   分发器上
分发器  Nginx+keepalvied
配置⾼可⽤    


keepalived 获得
#wget  http://www.keepalived.org/software/keepalived-2.0.8.tar.gz
keepalived 安装
#cat keepalived_install.sh
-------------------------------------------------
#!/bin/bash
pkg=keepalived-2.0.8.tar.gz

tar xf $pkg
yum -y install  kernel-devel
ln -s /usr/src/kernels/3.10.0-862.14.4.el7.x86_64/ /usr/src/linux
cd keepalived-2.0.8/
yum install openssl-* -y
./configure --prefix=/usr/local/keepalived
make
make install
mkdir -pv /etc/keepalived
cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/
ln -s /usr/local/keepalived/sbin/keepalived /sbin/
------------------------------------------------------------------------------

master.ayitula.com
#cat /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id NGINX_DEVEL
}

vrrp_script check_nginx {
          script "/etc/keepalived/nginx_pid.sh"
          interval 2
          fall 1
}

vrrp_instance nginx {
    state MASTER
    interface ens33
    mcast_src_ip 192.168.10.40
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }

  track_script {
                    check_nginx
          }
   
   virtual_ipaddress {
        192.168.10.213/24
    }
}

#chmod 755  /etc/keepalived/nginx_pid.sh
#cat /etc/keepalived/nginx_pid.sh

#!/bin/bash
nginx_kp_check () {
nginxpid=`ps -C nginx --no-header |wc -l`
if [ $nginxpid -eq 0 ];then
   /usr/local/nginx/sbin/nginx
      sleep 1
        nginxpid=`ps -C nginx --no-header |wc -l`
          if [ $nginxpid -eq 0 ];then
                    systemctl stop keepalived
          fi
fi
}

nginx_kp_check


#backuo.ayitula.com
#cat /etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
   router_id NGINX_DEVEL
}
vrrp_script check_nginx {
          script "/etc/keepalived/nginx_pid.sh"
          interval 2
          fall 1
}
vrrp_instance nginx {
    state BACKUP
    interface ens33
    mcast_src_ip 192.168.10.41
    virtual_router_id 51
    priority 90
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
  track_script {
                    check_nginx
          }
   virtual_ipaddress {
        192.168.10.213/24
    }
}